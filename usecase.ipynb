{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import List, Optional, Tuple\n",
    "try:\n",
    "    from pydeseq2.dds import DeseqDataSet\n",
    "    from pydeseq2.ds import DeseqStats\n",
    "except ImportError:\n",
    "    raise ImportError(\"Please install pyDESeq2: pip install pyDESeq2\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudobulk_and_deseq(\n",
    "    adata,\n",
    "    pseudobulk_group_cols: List[str],\n",
    "    condition_col: str,\n",
    "    comparisons: Optional[List[Tuple[str, str]]] = None,\n",
    "    design_factors: Optional[List[str]] = None,\n",
    "    min_samples_per_group: int = 5,\n",
    "    override_min_samples: bool = False,\n",
    "    pseudobulk_func: str = \"sum\",\n",
    "    min_cells_in_group: int = 1,\n",
    "    # Additional parameters passed to DESeqDataSet constructor\n",
    "    dds_kwargs: dict = {},\n",
    "    # Additional parameters passed to DeseqStats constructor\n",
    "    dds_stats_kwargs: dict = {}\n",
    "):\n",
    "    \"\"\"\n",
    "    Pseudobulk single-cell data from an AnnData object, then run pyDESeq2\n",
    "    differential expression. This version automatically adds 'log2_ncells'\n",
    "    as a covariate in the DESeq2 model. Now with added logging/printing\n",
    "    for debugging and clarity.\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata : anndata.AnnData\n",
    "        Single-cell data. Must have raw counts in `adata.X`.\n",
    "    pseudobulk_group_cols : List[str]\n",
    "        Columns in `adata.obs` that define each pseudobulk group. For example,\n",
    "        ['sample_id', 'cell_type', 'condition'].\n",
    "    condition_col : str\n",
    "        The metadata column (in `adata.obs`) that defines the primary condition\n",
    "        for differential analysis. Must be included in `pseudobulk_group_cols`\n",
    "        if it is part of the grouping.\n",
    "    comparisons : Optional[List[Tuple[str, str]]]\n",
    "        List of (conditionA, conditionB) pairs to compare. If None,\n",
    "        you must specify a comparison or handle it otherwise.\n",
    "    design_factors : Optional[List[str]]\n",
    "        Columns in the pseudobulk-level metadata to use in the DESeq design,\n",
    "        e.g. ['condition', 'batch']. If None, defaults to [condition_col].\n",
    "        Note that 'log2_ncells' is automatically added.\n",
    "    min_samples_per_group : int\n",
    "        Minimum required samples in each condition group for DESeq to run well.\n",
    "        DESeq2 typically recommends at least 5. If you have fewer, you can\n",
    "        set override_min_samples=True to proceed anyway.\n",
    "    override_min_samples : bool\n",
    "        If False and if any group has fewer than `min_samples_per_group` samples,\n",
    "        raises an error. If True, prints a warning and proceeds.\n",
    "    pseudobulk_func : str\n",
    "        Aggregation function to produce pseudobulk. Options: \"sum\", \"mean\", etc.\n",
    "        Typically \"sum\" is recommended for raw counts. Must be a valid pandas\n",
    "        groupby function.\n",
    "    min_cells_in_group : int\n",
    "        If a group has fewer than this number of cells, we discard it from\n",
    "        the pseudobulk matrix.\n",
    "    dds_kwargs : dict\n",
    "        Additional keyword arguments passed to `DeseqDataSet`.\n",
    "    dds_stats_kwargs : dict\n",
    "        Additional keyword arguments passed to `DeseqStats`.\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame containing DE results for all comparisons. Includes columns:\n",
    "        log2FoldChange, pvalue, padj, etc. Also has a 'comparison' column\n",
    "        indicating which conditionA_vs_conditionB the result corresponds to.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"========== Starting pseudobulk_and_deseq ==========\")\n",
    "    print(f\"Grouping columns: {pseudobulk_group_cols}\")\n",
    "    print(f\"Condition column: {condition_col}\")\n",
    "    print(f\"Comparisons: {comparisons}\")\n",
    "    print(f\"Design factors (initial): {design_factors}\")\n",
    "    print(f\"min_samples_per_group: {min_samples_per_group}, override_min_samples: {override_min_samples}\")\n",
    "    print(f\"Aggregation function: {pseudobulk_func}\")\n",
    "    print(f\"min_cells_in_group: {min_cells_in_group}\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "    # 0. Basic checks\n",
    "\n",
    "    print(\"Step 0: Checking columns in adata.obs...\")\n",
    "    for col in pseudobulk_group_cols:\n",
    "        if col not in adata.obs.columns:\n",
    "            raise ValueError(f\"'{col}' not found in adata.obs.\")\n",
    "    if condition_col not in adata.obs.columns:\n",
    "        raise ValueError(f\"'{condition_col}' not found in adata.obs.\")\n",
    "    if design_factors is not None:\n",
    "        for dfactor in design_factors:\n",
    "            if dfactor not in adata.obs.columns:\n",
    "                raise ValueError(f\"Design factor '{dfactor}' not found in adata.obs.\")\n",
    "    else:\n",
    "        design_factors = [condition_col]\n",
    "    if comparisons is None:\n",
    "        raise ValueError(\"No comparisons provided. Please provide a list of (condA, condB) tuples.\")\n",
    "    print(f\"Total cells in adata: {adata.n_obs}\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "\n",
    "    # 1. Create a single grouping key\n",
    "    grouping_key = \"pseudobulk_group_key\"\n",
    "    while grouping_key in adata.obs.columns:\n",
    "        grouping_key += \"_dup\"\n",
    "    adata.obs[grouping_key] = (\n",
    "        adata.obs[pseudobulk_group_cols]\n",
    "        .astype(str)\n",
    "        .apply(lambda x: \"--\".join(x), axis=1)\n",
    "    )\n",
    "    print(f\"Created grouping key '{grouping_key}' in adata.obs.\")\n",
    "    print(\"Example grouping key values:\")\n",
    "    print(adata.obs[grouping_key].head(5))\n",
    "    print(\"---------------------------------------------------\")\n",
    "\n",
    "    # 2. Convert to a cell-level counts DataFrame\n",
    "    print(\"Step 2: Creating cell_counts_df from adata.X...\")\n",
    "    if not hasattr(adata.X, \"toarray\"):\n",
    "        counts_matrix = adata.layers['raw']  # already dense\n",
    "        print(\"Data is already dense.\")\n",
    "    else:\n",
    "        counts_matrix = adata.layers['raw'].toarray()  # convert sparse to dense\n",
    "        print(\"Converted sparse matrix to dense.\")\n",
    "\n",
    "    # Round only the non-integer values to the next highest integer\n",
    "    non_integer_mask = (counts_matrix % 1 != 0)\n",
    "    counts_matrix[non_integer_mask] = np.ceil(counts_matrix[non_integer_mask])\n",
    "\n",
    "    # Verify that all values are now integers\n",
    "    assert np.all(counts_matrix % 1 == 0), \"There are still non-integer values!\"\n",
    "    print(\"Non-integer values rounded up successfully.\")\n",
    "\n",
    "    gene_names = adata.var_names.tolist()\n",
    "    cell_counts_df = pd.DataFrame(\n",
    "        counts_matrix,\n",
    "        columns=gene_names,\n",
    "        index=adata.obs.index\n",
    "    )\n",
    "    cell_counts_df[grouping_key] = adata.obs[grouping_key].values\n",
    "    print(f\"cell_counts_df shape: {cell_counts_df.shape}\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "    \n",
    "    # 3. Group and aggregate\n",
    "    print(\"Step 3: Grouping and aggregating...\")\n",
    "    grouped = cell_counts_df.groupby(grouping_key)\n",
    "    group_sizes = grouped.size()\n",
    "    valid_groups = group_sizes[group_sizes >= min_cells_in_group].index\n",
    "    print(f\"Number of total groups: {len(group_sizes)}\")\n",
    "    print(f\"Number of valid groups (>= {min_cells_in_group} cells): {len(valid_groups)}\")\n",
    "    if len(valid_groups) == 0:\n",
    "        raise ValueError(\"No groups found with at least min_cells_in_group cells.\")\n",
    "    cell_counts_df = cell_counts_df[cell_counts_df[grouping_key].isin(valid_groups)]\n",
    "    grouped = cell_counts_df.groupby(grouping_key)\n",
    "    if not hasattr(pd.core.groupby.generic.DataFrameGroupBy, pseudobulk_func):\n",
    "        raise ValueError(f\"Invalid pseudobulk_func '{pseudobulk_func}'. \"\n",
    "                         \"Must be a valid pandas groupby agg method.\")\n",
    "    pseudobulk_df = grouped.aggregate(pseudobulk_func)\n",
    "    print(\"Aggregated pseudobulk dataframe shape:\", pseudobulk_df.shape)\n",
    "    print(\"---------------------------------------------------\")\n",
    "    \n",
    "    # 3.1 Also store the actual number of cells in each group\n",
    "    n_cells_per_group = grouped.size()\n",
    "    if grouping_key in pseudobulk_df.columns:\n",
    "        pseudobulk_df.drop(columns=grouping_key, inplace=True, errors=\"ignore\")\n",
    "\n",
    "    # 4. Build pseudobulk-level metadata\n",
    "    print(\"Step 4: Building metadata for pseudobulk samples...\")\n",
    "    meta_list = []\n",
    "    for idx in pseudobulk_df.index:\n",
    "        split_vals = idx.split(\"--\")\n",
    "        meta_dict = {}\n",
    "        for col, val in zip(pseudobulk_group_cols, split_vals):\n",
    "            meta_dict[col] = val\n",
    "        meta_list.append(meta_dict)\n",
    "    pseudo_metadata = pd.DataFrame(meta_list, index=pseudobulk_df.index)\n",
    "    print(f\"pseudo_metadata shape: {pseudo_metadata.shape}\")\n",
    "    print(\"pseudo_metadata head:\")\n",
    "    print(pseudo_metadata.head(3))\n",
    "    print(\"---------------------------------------------------\")\n",
    "    \n",
    "    # 4.1 Add number of cells and log2 number of cells\n",
    "    pseudo_metadata[\"n_cells\"] = n_cells_per_group.reindex(pseudo_metadata.index)\n",
    "    pseudo_metadata[\"log2_ncells\"] = np.log2(pseudo_metadata[\"n_cells\"].astype(float))\n",
    "    print(\"Added 'n_cells' and 'log2_ncells' to pseudo_metadata.\")\n",
    "    print(pseudo_metadata[[\"n_cells\", \"log2_ncells\"]].head(3))\n",
    "    print(\"---------------------------------------------------\")\n",
    "\n",
    "    # 5. For each comparison, run DESeq\n",
    "    results_list = []\n",
    "    print(\"Step 5: Running DESeq comparisons...\")\n",
    "    for condA, condB in comparisons:\n",
    "        print(f\"  -> Comparison: {condB} vs {condA}\")\n",
    "        keep_idx = pseudo_metadata[condition_col].isin([condA, condB])\n",
    "        sub_counts = pseudobulk_df[keep_idx].copy()\n",
    "        sub_meta = pseudo_metadata[keep_idx].copy()\n",
    "        group_count_condA = (sub_meta[condition_col] == condA).sum()\n",
    "        group_count_condB = (sub_meta[condition_col] == condB).sum()\n",
    "        print(f\"     Condition '{condA}' sample count: {group_count_condA}\")\n",
    "        print(f\"     Condition '{condB}' sample count: {group_count_condB}\")\n",
    "        if not override_min_samples:\n",
    "            if group_count_condA < min_samples_per_group:\n",
    "                raise ValueError(\n",
    "                    f\"Condition '{condA}' has only {group_count_condA} samples. \"\n",
    "                    f\"Minimum required is {min_samples_per_group}. \"\n",
    "                    f\"Set override_min_samples=True to bypass.\"\n",
    "                )\n",
    "            if group_count_condB < min_samples_per_group:\n",
    "                raise ValueError(\n",
    "                    f\"Condition '{condB}' has only {group_count_condB} samples. \"\n",
    "                    f\"Minimum required is {min_samples_per_group}. \"\n",
    "                    f\"Set override_min_samples=True to bypass.\"\n",
    "                )\n",
    "        else:\n",
    "            if (group_count_condA < min_samples_per_group) or (group_count_condB < min_samples_per_group):\n",
    "                print(\n",
    "                    f\"     WARNING: {condA} has {group_count_condA} samples, \"\n",
    "                    f\"{condB} has {group_count_condB} samples. \"\n",
    "                    f\"Continuing because override_min_samples=True.\"\n",
    "                )\n",
    "        # Build the local design\n",
    "        if condition_col not in design_factors:\n",
    "            design_factors_local = [condition_col] + design_factors\n",
    "        else:\n",
    "            design_factors_local = design_factors[:]\n",
    "        if \"log2_ncells\" not in design_factors_local:\n",
    "            design_factors_local.append(\"log2_ncells\")\n",
    "\n",
    "        reference_level = [condition_col, condA]  # sets condA as the reference\n",
    "        print(\"     Using design factors:\", f\"~ {' + '.join(design_factors_local)}\")\n",
    "        print(\"     sub_counts shape:\", sub_counts.shape)\n",
    "        print(\"     sub_meta shape:\", sub_meta.shape)\n",
    "        print(\"     reference level:\", reference_level)\n",
    "\n",
    "        # Initialize DeseqDataSet\n",
    "        print(\"     Initializing DeseqDataSet...\")\n",
    "        dds = DeseqDataSet(\n",
    "            counts=sub_counts,\n",
    "            metadata=sub_meta,\n",
    "            design_factors = design_factors_local,\n",
    "            ref_level=reference_level, \n",
    "            **dds_kwargs\n",
    "        )\n",
    "        print(\"     Running dds.deseq2()...\")\n",
    "        dds.deseq2()\n",
    "        print(\"     Initializing DeseqStats and computing results...\")\n",
    "        stat_res = DeseqStats(dds, **dds_stats_kwargs)\n",
    "        stat_res.summary()\n",
    "        res_df = stat_res.results_df.copy()\n",
    "        res_df[\"comparison\"] = f\"{condB}_vs_{condA}\"\n",
    "        res_df[\"condA\"] = condA\n",
    "        res_df[\"condB\"] = condB\n",
    "        res_df[\"gene\"] = res_df.index\n",
    "        print(\"     DE results shape:\", res_df.shape)\n",
    "        print(\"     DE results head:\")\n",
    "        print(res_df.head(3))\n",
    "        results_list.append(res_df)\n",
    "    final_results = pd.concat(results_list, axis=0)\n",
    "    print(\"All comparisons finished. final_results shape:\", final_results.shape)\n",
    "    print(\"========== pseudobulk_and_deseq Completed ==========\")\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 921278 × 42811\n",
       "    obs: 'sample', 'total_counts', 'n_genes', 'batch', 'n_counts', 'cell_type', 'n_genes_by_counts', 'pct_counts_mt', 'total_counts_mt', 'label:scanvi', 'scvi-global-0.5_leiden', 'scvi-global-1.0_leiden', 'scvi-global-2_leiden', 'scvi-global-1.5_leiden', 'scanvi-global-0.5_leiden', 'scanvi-global-2_leiden', 'scanvi-global-1.0_leiden', 'scanvi-global-1.5_leiden', 'dataset', 'patient', 'sex', 'condition', 'tissue', 'n_cells (after filtering)', 'disease status', 'disease location', 'sequencing protocol', 'biopsy type', 'tissue depth', 'montreal classification_age at diagnosis', 'age group (at sample collection)', 'montreal classification_cd location ', 'montreal classification_ cd behavior', 'ses-cd ', 'montreal classification_ uc extensity', 'montreal classification_ uc severity', 'mayo score-uc', 'medication_antidiarrheal (lomotil, imodium, dto)', 'medication_5_asa', 'medication_biologics ', 'medication_biologics (monoclonal antibody medication)', 'medication_target (anti-tnf, anti-il23, anti-integrin α4β7, anti-integrin α4β1, ...)', 'medication_steroid', 'medication_immunomodulators (azathioprine, methotrexate, mercaptopurine)', 'medication_antibiotic (flaygl, cipro, xifaxin, levaquin)', 'smoking', 'enrichment_for_specific_cell_type', 'annotation:coarse', 'annotation(old):coarse', 'annotation(old):fine', 'annotation:coarse:cleaned'\n",
       "    uns: 'annotation(old):coarse_colors', 'annotation:coarse_colors', 'dataset_colors', 'neighbors', 'scanvi-global-0.5_characteristic_genes', 'scanvi-global-0.5_paga', 'scanvi-global-1.0_characteristic_genes', 'scanvi-global-1.0_leiden', 'scanvi-global-1.0_paga', 'scanvi-global-1.5_characteristic_genes', 'scanvi-global-1.5_paga', 'scanvi-global-2_characteristic_genes', 'scanvi-global-2_paga', 'scvi-global-0.5_characteristic_genes', 'scvi-global-0.5_paga', 'scvi-global-1.0_characteristic_genes', 'scvi-global-1.0_leiden', 'scvi-global-1.0_paga', 'scvi-global-1.5_characteristic_genes', 'scvi-global-1.5_paga', 'scvi-global-2_characteristic_genes', 'scvi-global-2_paga', 'umap'\n",
       "    obsm: 'X_scanvi-global_umap', 'X_scvi-global_umap', 'scanvi', 'scvi'\n",
       "    layers: 'log1p', 'raw'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read_h5ad('/nfs/data/COST_IBD/versions/IBD/03_00_00/03_00_03_sub/adata_core_cellxgene_cleaned_coarse_annotation.h5ad')\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_indices = np.random.choice(adata.n_obs, size=2000, replace=False)\n",
    "#adata_subset = adata[random_indices].copy()\n",
    "\n",
    "adata_subset = sc.read_h5ad('test_subset_ibd.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Starting pseudobulk_and_deseq ==========\n",
      "Grouping columns: ['sample', 'annotation:coarse:cleaned', 'condition', 'smoking']\n",
      "Condition column: condition\n",
      "Comparisons: [('HC', 'UC'), ('HC', 'CD')]\n",
      "Design factors (initial): ['condition', 'smoking']\n",
      "min_samples_per_group: 5, override_min_samples: False\n",
      "Aggregation function: sum\n",
      "min_cells_in_group: 3\n",
      "---------------------------------------------------\n",
      "Step 0: Checking columns in adata.obs...\n",
      "Total cells in adata: 10000\n",
      "---------------------------------------------------\n",
      "Created grouping key 'pseudobulk_group_key' in adata.obs.\n",
      "Example grouping key values:\n",
      "original_index\n",
      "smillie_N7.LPB.TAACTCACTGCTAG       Smillie_N7_B--B_plasma--UC--Never\n",
      "kong_N119540_L1-CAGCAATTCCTTATAC       N119540_1--T_NK_ILC--CD--Never\n",
      "kong_N175041_N1-GAAGCAGGTTGATTGC        N175041_1--stromal--CD--Never\n",
      "smillie_N24.LPA.TGCTACCTCCCGACTT    Smillie_N24_A--stromal--UC--Never\n",
      "kong_N176196_L2-TACCCGTGTATGGAGC       N176196_2--T_NK_ILC--CD--Never\n",
      "Name: pseudobulk_group_key, dtype: object\n",
      "---------------------------------------------------\n",
      "Step 2: Creating cell_counts_df from adata.X...\n",
      "Converted sparse matrix to dense.\n",
      "Non-integer values rounded up successfully.\n",
      "cell_counts_df shape: (10000, 42812)\n",
      "---------------------------------------------------\n",
      "Step 3: Grouping and aggregating...\n",
      "Number of total groups: 1090\n",
      "Number of valid groups (>= 3 cells): 762\n",
      "Aggregated pseudobulk dataframe shape: (762, 42811)\n",
      "---------------------------------------------------\n",
      "Step 4: Building metadata for pseudobulk samples...\n",
      "pseudo_metadata shape: (762, 4)\n",
      "pseudo_metadata head:\n",
      "                           sample annotation:coarse:cleaned condition  smoking\n",
      "pseudobulk_group_key                                                          \n",
      "198--B_plasma--UC--Unknown    198                  B_plasma        UC  Unknown\n",
      "198--T_NK_ILC--UC--Unknown    198                  T_NK_ILC        UC  Unknown\n",
      "198--stromal--UC--Unknown     198                   stromal        UC  Unknown\n",
      "---------------------------------------------------\n",
      "Added 'n_cells' and 'log2_ncells' to pseudo_metadata.\n",
      "                            n_cells  log2_ncells\n",
      "pseudobulk_group_key                            \n",
      "198--B_plasma--UC--Unknown       30     4.906891\n",
      "198--T_NK_ILC--UC--Unknown        3     1.584963\n",
      "198--stromal--UC--Unknown         6     2.584963\n",
      "---------------------------------------------------\n",
      "Step 5: Running DESeq comparisons...\n",
      "  -> Comparison: UC vs HC\n",
      "     Condition 'HC' sample count: 210\n",
      "     Condition 'UC' sample count: 238\n",
      "     Using design factors: ~ condition + smoking + log2_ncells\n",
      "     sub_counts shape: (448, 42811)\n",
      "     sub_meta shape: (448, 6)\n",
      "     reference level: ['condition', 'HC']\n",
      "     Initializing DeseqDataSet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_559100/1023821366.py:227: UserWarning: Same factor names in the design contain underscores ('_'). They will\n",
      "                be converted to hyphens ('-').\n",
      "  dds = DeseqDataSet(\n",
      "Fitting size factors...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Running dds.deseq2()...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... done in 0.54 seconds.\n",
      "\n",
      "Fitting dispersions...\n",
      "... done in 102.53 seconds.\n",
      "\n",
      "Fitting dispersion trend curve...\n",
      "/nfs/home/students/adietrich/.conda/envs/scarches/lib/python3.9/site-packages/pydeseq2/dds.py:727: UserWarning: The dispersion trend curve fitting did not converge. Switching to a mean-based dispersion trend.\n",
      "  self._fit_parametric_dispersion_trend(vst)\n",
      "... done in 0.64 seconds.\n",
      "\n",
      "Fitting MAP dispersions...\n",
      "... done in 152.08 seconds.\n",
      "\n",
      "Fitting LFCs...\n",
      "... done in 293.06 seconds.\n",
      "\n",
      "Calculating cook's distance...\n",
      "... done in 1.03 seconds.\n",
      "\n",
      "Replacing 24878 outlier genes.\n",
      "\n",
      "Fitting dispersions...\n",
      "... done in 91.23 seconds.\n",
      "\n",
      "Fitting MAP dispersions...\n",
      "... done in 135.91 seconds.\n",
      "\n",
      "Fitting LFCs...\n",
      "... done in 281.06 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Initializing DeseqStats and computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Wald tests...\n",
      "... done in 20.05 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2 fold change & Wald test p-value: log2-ncells 2.0 vs 1.584962500721156\n",
      "                     baseMean  log2FoldChange     lfcSE      stat    pvalue  \\\n",
      "5S_rRNA              0.000000             NaN       NaN       NaN       NaN   \n",
      "7SK                  0.414558       -0.158692  6.667469 -0.023801  0.981011   \n",
      "7SK.1                0.006479       -0.127310  6.668549 -0.019091  0.984768   \n",
      "7SK.2                1.876246        0.997783  6.642888  0.150203  0.880604   \n",
      "7SK_ENSG00000232512  0.000000             NaN       NaN       NaN       NaN   \n",
      "...                       ...             ...       ...       ...       ...   \n",
      "hsa-mir-490          0.000000             NaN       NaN       NaN       NaN   \n",
      "hsa-mir-6080         0.030987       -0.220023  6.667754 -0.032998  0.973676   \n",
      "hsa-mir-8072         0.199855       -0.210286  5.197445 -0.040459  0.967727   \n",
      "pL63_blaR            0.030112       -0.135003  6.668162 -0.020246  0.983847   \n",
      "snoU13               0.021866       -0.123285  6.668961 -0.018486  0.985251   \n",
      "\n",
      "                     padj  \n",
      "5S_rRNA               NaN  \n",
      "7SK                   NaN  \n",
      "7SK.1                 NaN  \n",
      "7SK.2                 NaN  \n",
      "7SK_ENSG00000232512   NaN  \n",
      "...                   ...  \n",
      "hsa-mir-490           NaN  \n",
      "hsa-mir-6080          NaN  \n",
      "hsa-mir-8072          NaN  \n",
      "pL63_blaR             NaN  \n",
      "snoU13                NaN  \n",
      "\n",
      "[42811 rows x 6 columns]\n",
      "     DE results shape: (42811, 10)\n",
      "     DE results head:\n",
      "         baseMean  log2FoldChange     lfcSE      stat    pvalue  padj  \\\n",
      "5S_rRNA  0.000000             NaN       NaN       NaN       NaN   NaN   \n",
      "7SK      0.414558       -0.158692  6.667469 -0.023801  0.981011   NaN   \n",
      "7SK.1    0.006479       -0.127310  6.668549 -0.019091  0.984768   NaN   \n",
      "\n",
      "        comparison condA condB     gene  \n",
      "5S_rRNA   UC_vs_HC    HC    UC  5S_rRNA  \n",
      "7SK       UC_vs_HC    HC    UC      7SK  \n",
      "7SK.1     UC_vs_HC    HC    UC    7SK.1  \n",
      "  -> Comparison: CD vs HC\n",
      "     Condition 'HC' sample count: 210\n",
      "     Condition 'CD' sample count: 310\n",
      "     Using design factors: ~ condition + smoking + log2_ncells\n",
      "     sub_counts shape: (520, 42811)\n",
      "     sub_meta shape: (520, 6)\n",
      "     reference level: ['condition', 'HC']\n",
      "     Initializing DeseqDataSet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_559100/1023821366.py:227: UserWarning: Same factor names in the design contain underscores ('_'). They will\n",
      "                be converted to hyphens ('-').\n",
      "  dds = DeseqDataSet(\n",
      "Fitting size factors...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Running dds.deseq2()...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... done in 0.57 seconds.\n",
      "\n",
      "Fitting dispersions...\n",
      "... done in 116.40 seconds.\n",
      "\n",
      "Fitting dispersion trend curve...\n",
      "/nfs/home/students/adietrich/.conda/envs/scarches/lib/python3.9/site-packages/pydeseq2/dds.py:727: UserWarning: The dispersion trend curve fitting did not converge. Switching to a mean-based dispersion trend.\n",
      "  self._fit_parametric_dispersion_trend(vst)\n",
      "... done in 0.95 seconds.\n",
      "\n",
      "Fitting MAP dispersions...\n",
      "... done in 169.10 seconds.\n",
      "\n",
      "Fitting LFCs...\n",
      "... done in 270.88 seconds.\n",
      "\n",
      "Calculating cook's distance...\n",
      "... done in 1.53 seconds.\n",
      "\n",
      "Replacing 26420 outlier genes.\n",
      "\n",
      "Fitting dispersions...\n",
      "... done in 100.23 seconds.\n",
      "\n",
      "Fitting MAP dispersions...\n",
      "... done in 156.52 seconds.\n",
      "\n",
      "Fitting LFCs...\n",
      "... done in 242.31 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Initializing DeseqStats and computing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Wald tests...\n",
      "... done in 19.31 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2 fold change & Wald test p-value: log2-ncells 2.0 vs 1.584962500721156\n",
      "                     baseMean  log2FoldChange     lfcSE      stat    pvalue  \\\n",
      "5S_rRNA              0.000000             NaN       NaN       NaN       NaN   \n",
      "7SK                  0.064560       -0.364848  5.622763 -0.064888  0.948263   \n",
      "7SK.1                0.000000             NaN       NaN       NaN       NaN   \n",
      "7SK.2                0.000000             NaN       NaN       NaN       NaN   \n",
      "7SK_ENSG00000232512  0.000000             NaN       NaN       NaN       NaN   \n",
      "...                       ...             ...       ...       ...       ...   \n",
      "hsa-mir-490          0.000000             NaN       NaN       NaN       NaN   \n",
      "hsa-mir-6080         0.008352       -0.364808  5.622797 -0.064880  0.948269   \n",
      "hsa-mir-8072         0.074415       -0.372757  1.866777 -0.199679  0.841731   \n",
      "pL63_blaR            0.011997       -0.365023  5.622749 -0.064919  0.948239   \n",
      "snoU13               0.005510       -0.367616  5.622781 -0.065380  0.947872   \n",
      "\n",
      "                         padj  \n",
      "5S_rRNA                   NaN  \n",
      "7SK                  0.998719  \n",
      "7SK.1                     NaN  \n",
      "7SK.2                     NaN  \n",
      "7SK_ENSG00000232512       NaN  \n",
      "...                       ...  \n",
      "hsa-mir-490               NaN  \n",
      "hsa-mir-6080         0.998719  \n",
      "hsa-mir-8072         0.998719  \n",
      "pL63_blaR            0.998719  \n",
      "snoU13               0.998719  \n",
      "\n",
      "[42811 rows x 6 columns]\n",
      "     DE results shape: (42811, 10)\n",
      "     DE results head:\n",
      "         baseMean  log2FoldChange     lfcSE      stat    pvalue      padj  \\\n",
      "5S_rRNA   0.00000             NaN       NaN       NaN       NaN       NaN   \n",
      "7SK       0.06456       -0.364848  5.622763 -0.064888  0.948263  0.998719   \n",
      "7SK.1     0.00000             NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "        comparison condA condB     gene  \n",
      "5S_rRNA   CD_vs_HC    HC    CD  5S_rRNA  \n",
      "7SK       CD_vs_HC    HC    CD      7SK  \n",
      "7SK.1     CD_vs_HC    HC    CD    7SK.1  \n",
      "All comparisons finished. final_results shape: (85622, 10)\n",
      "========== pseudobulk_and_deseq Completed ==========\n",
      "                     baseMean  log2FoldChange     lfcSE      stat    pvalue  \\\n",
      "5S_rRNA              0.000000             NaN       NaN       NaN       NaN   \n",
      "7SK                  0.414558       -0.158692  6.667469 -0.023801  0.981011   \n",
      "7SK.1                0.006479       -0.127310  6.668549 -0.019091  0.984768   \n",
      "7SK.2                1.876246        0.997783  6.642888  0.150203  0.880604   \n",
      "7SK_ENSG00000232512  0.000000             NaN       NaN       NaN       NaN   \n",
      "\n",
      "                     padj comparison condA condB                 gene  \n",
      "5S_rRNA               NaN   UC_vs_HC    HC    UC              5S_rRNA  \n",
      "7SK                   NaN   UC_vs_HC    HC    UC                  7SK  \n",
      "7SK.1                 NaN   UC_vs_HC    HC    UC                7SK.1  \n",
      "7SK.2                 NaN   UC_vs_HC    HC    UC                7SK.2  \n",
      "7SK_ENSG00000232512   NaN   UC_vs_HC    HC    UC  7SK_ENSG00000232512  \n"
     ]
    }
   ],
   "source": [
    "# Suppose your AnnData has:\n",
    "#   adata.obs['sample_id'] for sample\n",
    "#   adata.obs['cell_type'] for cell types\n",
    "#   adata.obs['condition'] for conditions\n",
    "#   adata.X is raw UMI counts\n",
    "# Example: pseudobulk by sample + cell_type + condition,\n",
    "# run DESeq comparing multiple condition pairs,\n",
    "# with some additional design factor (like batch).\n",
    "design_factors = ['condition', 'smoking']  # batch must exist in adata.obs\n",
    "comparisons = [\n",
    "    (\"HC\", \"UC\"),\n",
    "    (\"HC\", \"CD\")\n",
    "]\n",
    "res = pseudobulk_and_deseq(\n",
    "    adata=adata_subset,\n",
    "    pseudobulk_group_cols=[\"sample\", \"annotation:coarse:cleaned\", \"condition\", \"smoking\"],\n",
    "    condition_col=\"condition\",\n",
    "    comparisons=comparisons,\n",
    "    design_factors=design_factors,\n",
    "    min_samples_per_group=5,\n",
    "    override_min_samples=False,\n",
    "    pseudobulk_func=\"sum\",          # sum is typical for raw counts\n",
    "    min_cells_in_group=3,           # minimum number of cells per group before aggregating\n",
    "    dds_kwargs={},  # example advanced parameter\n",
    "    dds_stats_kwargs={\"alpha\": 0.05} # e.g. FDR threshold\n",
    ")\n",
    "# Check the output\n",
    "print(res.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>annotation:coarse:cleaned</th>\n",
       "      <th>condition</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smillie_N7.LPB.TAACTCACTGCTAG</th>\n",
       "      <td>Smillie_N7_B</td>\n",
       "      <td>B_plasma</td>\n",
       "      <td>UC</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kong_N119540_L1-CAGCAATTCCTTATAC</th>\n",
       "      <td>N119540_1</td>\n",
       "      <td>T_NK_ILC</td>\n",
       "      <td>CD</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kong_N175041_N1-GAAGCAGGTTGATTGC</th>\n",
       "      <td>N175041_1</td>\n",
       "      <td>stromal</td>\n",
       "      <td>CD</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smillie_N24.LPA.TGCTACCTCCCGACTT</th>\n",
       "      <td>Smillie_N24_A</td>\n",
       "      <td>stromal</td>\n",
       "      <td>UC</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kong_N176196_L2-TACCCGTGTATGGAGC</th>\n",
       "      <td>N176196_2</td>\n",
       "      <td>T_NK_ILC</td>\n",
       "      <td>CD</td>\n",
       "      <td>Never</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sample annotation:coarse:cleaned  \\\n",
       "original_index                                                              \n",
       "smillie_N7.LPB.TAACTCACTGCTAG      Smillie_N7_B                  B_plasma   \n",
       "kong_N119540_L1-CAGCAATTCCTTATAC      N119540_1                  T_NK_ILC   \n",
       "kong_N175041_N1-GAAGCAGGTTGATTGC      N175041_1                   stromal   \n",
       "smillie_N24.LPA.TGCTACCTCCCGACTT  Smillie_N24_A                   stromal   \n",
       "kong_N176196_L2-TACCCGTGTATGGAGC      N176196_2                  T_NK_ILC   \n",
       "\n",
       "                                 condition smoking  \n",
       "original_index                                      \n",
       "smillie_N7.LPB.TAACTCACTGCTAG           UC   Never  \n",
       "kong_N119540_L1-CAGCAATTCCTTATAC        CD   Never  \n",
       "kong_N175041_N1-GAAGCAGGTTGATTGC        CD   Never  \n",
       "smillie_N24.LPA.TGCTACCTCCCGACTT        UC   Never  \n",
       "kong_N176196_L2-TACCCGTGTATGGAGC        CD   Never  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_subset.obs[[\"sample\", \"annotation:coarse:cleaned\", \"condition\", \"smoking\"]].head()\n",
    "\n",
    "pseudobulk_group_cols=[\"sample\", \"annotation:coarse:cleaned\", \"condition\", \"smoking\"]\n",
    "condition_col=\"condition\"\n",
    "design_factors = ['condition', 'smoking'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create a single grouping key\n",
    "grouping_key = \"pseudobulk_group_key\"\n",
    "while grouping_key in adata_subset.obs.columns:\n",
    "    grouping_key += \"_dup\"\n",
    "adata_subset.obs[grouping_key] = (\n",
    "    adata_subset.obs[pseudobulk_group_cols]\n",
    "    .astype(str)\n",
    "    .apply(lambda x: \"--\".join(x), axis=1)\n",
    ")\n",
    "print(f\"Created grouping key '{grouping_key}' in adata.obs.\")\n",
    "print(\"Example grouping key values:\")\n",
    "print(adata_subset.obs[grouping_key].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Convert to a cell-level counts DataFrame\n",
    "print(\"Step 2: Creating cell_counts_df from adata.X...\")\n",
    "if not hasattr(adata_subset.X, \"toarray\"):\n",
    "    counts_matrix = adata_subset.layers['raw']  # already dense\n",
    "    print(\"Data is already dense.\")\n",
    "else:\n",
    "    counts_matrix = adata_subset.layers['raw'].toarray()  # convert sparse to dense\n",
    "    print(\"Converted sparse matrix to dense.\")\n",
    "\n",
    "# Round only the non-integer values to the next highest integer\n",
    "non_integer_mask = (counts_matrix % 1 != 0)\n",
    "counts_matrix[non_integer_mask] = np.ceil(counts_matrix[non_integer_mask])\n",
    "\n",
    "# Verify that all values are now integers\n",
    "assert np.all(counts_matrix % 1 == 0), \"There are still non-integer values!\"\n",
    "print(\"Non-integer values rounded up successfully.\")\n",
    "\n",
    "gene_names = adata_subset.var_names.tolist()\n",
    "cell_counts_df = pd.DataFrame(\n",
    "    counts_matrix,\n",
    "    columns=gene_names,\n",
    "    index=adata_subset.obs.index\n",
    ")\n",
    "cell_counts_df[grouping_key] = adata_subset.obs[grouping_key].values\n",
    "print(f\"cell_counts_df shape: {cell_counts_df.shape}\")\n",
    "print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Group and aggregate\n",
    "print(\"Step 3: Grouping and aggregating...\")\n",
    "grouped = cell_counts_df.groupby(grouping_key)\n",
    "group_sizes = grouped.size()\n",
    "valid_groups = group_sizes[group_sizes >= min_cells_in_group].index\n",
    "print(f\"Number of total groups: {len(group_sizes)}\")\n",
    "print(f\"Number of valid groups (>= {min_cells_in_group} cells): {len(valid_groups)}\")\n",
    "if len(valid_groups) == 0:\n",
    "    raise ValueError(\"No groups found with at least min_cells_in_group cells.\")\n",
    "cell_counts_df = cell_counts_df[cell_counts_df[grouping_key].isin(valid_groups)]\n",
    "grouped = cell_counts_df.groupby(grouping_key)\n",
    "if not hasattr(pd.core.groupby.generic.DataFrameGroupBy, pseudobulk_func):\n",
    "    raise ValueError(f\"Invalid pseudobulk_func '{pseudobulk_func}'. \"\n",
    "                        \"Must be a valid pandas groupby agg method.\")\n",
    "pseudobulk_df = grouped.aggregate(pseudobulk_func)\n",
    "print(\"Aggregated pseudobulk dataframe shape:\", pseudobulk_df.shape)\n",
    "print(\"---------------------------------------------------\")\n",
    "\n",
    "# 3.1 Also store the actual number of cells in each group\n",
    "n_cells_per_group = grouped.size()\n",
    "if grouping_key in pseudobulk_df.columns:\n",
    "    pseudobulk_df.drop(columns=grouping_key, inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Build pseudobulk-level metadata\n",
    "print(\"Step 4: Building metadata for pseudobulk samples...\")\n",
    "meta_list = []\n",
    "for idx in pseudobulk_df.index:\n",
    "    split_vals = idx.split(\"--\")\n",
    "    meta_dict = {}\n",
    "    for col, val in zip(pseudobulk_group_cols, split_vals):\n",
    "        meta_dict[col] = val\n",
    "    meta_list.append(meta_dict)\n",
    "pseudo_metadata = pd.DataFrame(meta_list, index=pseudobulk_df.index)\n",
    "print(f\"pseudo_metadata shape: {pseudo_metadata.shape}\")\n",
    "print(\"pseudo_metadata head:\")\n",
    "print(pseudo_metadata.head(3))\n",
    "print(\"---------------------------------------------------\")\n",
    "\n",
    "# 4.1 Add number of cells and log2 number of cells\n",
    "pseudo_metadata[\"n_cells\"] = n_cells_per_group.reindex(pseudo_metadata.index)\n",
    "pseudo_metadata[\"log2_ncells\"] = np.log2(pseudo_metadata[\"n_cells\"].astype(float))\n",
    "print(\"Added 'n_cells' and 'log2_ncells' to pseudo_metadata.\")\n",
    "print(pseudo_metadata[[\"n_cells\", \"log2_ncells\"]].head(3))\n",
    "print(\"---------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. For each comparison, run DESeq\n",
    "results_list = []\n",
    "print(\"Step 5: Running DESeq comparisons...\")\n",
    "for condA, condB in comparisons:\n",
    "    print(f\"  -> Comparison: {condB} vs {condA}\")\n",
    "    keep_idx = pseudo_metadata[condition_col].isin([condA, condB])\n",
    "    sub_counts = pseudobulk_df[keep_idx].copy()\n",
    "    sub_meta = pseudo_metadata[keep_idx].copy()\n",
    "    group_count_condA = (sub_meta[condition_col] == condA).sum()\n",
    "    group_count_condB = (sub_meta[condition_col] == condB).sum()\n",
    "    print(f\"     Condition '{condA}' sample count: {group_count_condA}\")\n",
    "    print(f\"     Condition '{condB}' sample count: {group_count_condB}\")\n",
    "    if not override_min_samples:\n",
    "        if group_count_condA < min_samples_per_group:\n",
    "            raise ValueError(\n",
    "                f\"Condition '{condA}' has only {group_count_condA} samples. \"\n",
    "                f\"Minimum required is {min_samples_per_group}. \"\n",
    "                f\"Set override_min_samples=True to bypass.\"\n",
    "            )\n",
    "        if group_count_condB < min_samples_per_group:\n",
    "            raise ValueError(\n",
    "                f\"Condition '{condB}' has only {group_count_condB} samples. \"\n",
    "                f\"Minimum required is {min_samples_per_group}. \"\n",
    "                f\"Set override_min_samples=True to bypass.\"\n",
    "            )\n",
    "    else:\n",
    "        if (group_count_condA < min_samples_per_group) or (group_count_condB < min_samples_per_group):\n",
    "            print(\n",
    "                f\"     WARNING: {condA} has {group_count_condA} samples, \"\n",
    "                f\"{condB} has {group_count_condB} samples. \"\n",
    "                f\"Continuing because override_min_samples=True.\"\n",
    "            )\n",
    "    # Build the local design\n",
    "    if condition_col not in design_factors:\n",
    "        design_factors_local = [condition_col] + design_factors\n",
    "    else:\n",
    "        design_factors_local = design_factors[:]\n",
    "    if \"log2_ncells\" not in design_factors_local:\n",
    "        design_factors_local.append(\"log2_ncells\")\n",
    "\n",
    "    reference_level = [condition_col, condA]  # sets condA as the reference\n",
    "    print(\"     Using design factors:\", f\"~ {' + '.join(design_factors_local)}\")\n",
    "    print(\"     sub_counts shape:\", sub_counts.shape)\n",
    "    print(\"     sub_meta shape:\", sub_meta.shape)\n",
    "    print(\"     reference level:\", reference_level)\n",
    "\n",
    "    # Initialize DeseqDataSet\n",
    "    print(\"     Initializing DeseqDataSet...\")\n",
    "    dds = DeseqDataSet(\n",
    "        counts=sub_counts,\n",
    "        metadata=sub_meta,\n",
    "        design_factors = design_factors_local,\n",
    "        ref_level=reference_level, \n",
    "        **dds_kwargs\n",
    "    )\n",
    "    print(\"     Running dds.deseq2()...\")\n",
    "    dds.deseq2()\n",
    "    print(\"     Initializing DeseqStats and computing results...\")\n",
    "    stat_res = DeseqStats(dds, **dds_stats_kwargs)\n",
    "    stat_res.summary()\n",
    "    res_df = stat_res.results_df.copy()\n",
    "    res_df[\"comparison\"] = f\"{condB}_vs_{condA}\"\n",
    "    res_df[\"condA\"] = condA\n",
    "    res_df[\"condB\"] = condB\n",
    "    res_df[\"gene\"] = res_df.index\n",
    "    print(\"     DE results shape:\", res_df.shape)\n",
    "    print(\"     DE results head:\")\n",
    "    print(res_df.head(3))\n",
    "    results_list.append(res_df)\n",
    "final_results = pd.concat(results_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              sample_id      gene     value\n",
      "0  parikh_GSM3214209_TCAGGATAGAAGGTGA-1  C18orf32  0.333333\n",
      "1  parikh_GSM3214209_TCAGGATAGAAGGTGA-1     C1QBP  1.500000\n",
      "2  parikh_GSM3214209_TCAGGATAGAAGGTGA-1     CLDN7  1.500000\n",
      "3  parikh_GSM3214209_TCAGGATAGAAGGTGA-1    CORO1B  0.500000\n",
      "4  parikh_GSM3214209_TCAGGATAGAAGGTGA-1     DGAT1  3.500000\n"
     ]
    }
   ],
   "source": [
    "mask = (adata_subset.layers['raw'].toarray() % 1 != 0)\n",
    "\n",
    "rows, cols = np.where(mask)\n",
    "\n",
    "sample_ids = adata_subset.obs_names[rows]  # Sample names\n",
    "gene_names = adata_subset.var_names[cols]  # Gene names\n",
    "non_integer_values = adata_subset.layers['raw'].toarray()[rows, cols]\n",
    "\n",
    "df_non_integer = pd.DataFrame({\n",
    "    \"sample_id\": sample_ids,\n",
    "    \"gene\": gene_names,\n",
    "    \"value\": non_integer_values\n",
    "})\n",
    "\n",
    "# Display the first few cases\n",
    "print(df_non_integer.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices2 = np.random.choice(adata.n_obs, size=1000, replace=False)\n",
    "adata_subset2 = adata[random_indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_subset2.write_h5ad('test_subset_ibd.h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scarches",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
